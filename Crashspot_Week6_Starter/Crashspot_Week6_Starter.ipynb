{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6484b585",
   "metadata": {},
   "source": [
    "# Crashspot – Week 6 Starter\n",
    "\n",
    "**Focus:** Model enhancement + class imbalance handling + third model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e36985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             RocCurveDisplay, PrecisionRecallDisplay, \n",
    "                             accuracy_score, f1_score)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Optional: SMOTE (may not be installed). We'll try and fallback gracefully.\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    HAS_SMOTE = True\n",
    "except Exception as e:\n",
    "    HAS_SMOTE = False\n",
    "    print(\"SMOTE not available; proceeding without it. To enable: pip install imbalanced-learn\")\n",
    "\n",
    "# Paths (assuming this notebook lives in Crashspot/notebooks/)\n",
    "DATA_PATH = \"../data_clean/week5_features.csv\"\n",
    "FIG_DIR = \"../output/figures\"\n",
    "MODEL_DIR = \"../models\"\n",
    "\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Load Week 5 engineered dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bc243",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Features/target\n",
    "target = \"target_multiveh\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Train/Val/Test split: 70/15/15\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "y.value_counts(normalize=True).rename(\"class_ratio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7637816",
   "metadata": {},
   "source": [
    "## Strategy A: Class weights (balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f97fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression with class_weight\n",
    "lr = LogisticRegression(max_iter=1000, solver=\"liblinear\", class_weight=\"balanced\")\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest with class_weight\n",
    "rf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Gradient Boosting (no native class_weight) — baseline third model\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "models = {\"LogReg_bal\": lr, \"RF_bal\": rf, \"GB\": gb}\n",
    "\n",
    "# Validate\n",
    "val_rows = []\n",
    "for name, m in models.items():\n",
    "    y_pred = m.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    val_rows.append({\"model\": name, \"val_accuracy\": acc, \"val_f1\": f1})\n",
    "    print(f\"\\n=== {name} (Validation) ===\")\n",
    "    print(classification_report(y_val, y_pred, digits=3))\n",
    "pd.DataFrame(val_rows).sort_values(\"val_f1\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0784da2",
   "metadata": {},
   "source": [
    "## Strategy B: Oversampling with SMOTE (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94327f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if HAS_SMOTE:\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "    print(\"After SMOTE:\", X_train_sm.shape, \"class balance:\", y_train_sm.value_counts())\n",
    "\n",
    "    lr_sm = LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
    "    rf_sm = RandomForestClassifier(random_state=42)\n",
    "    gb_sm = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "    for m in (lr_sm, rf_sm, gb_sm):\n",
    "        m.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "    models_sm = {\"LogReg_SMOTE\": lr_sm, \"RF_SMOTE\": rf_sm, \"GB_SMOTE\": gb_sm}\n",
    "\n",
    "    val_rows_sm = []\n",
    "    for name, m in models_sm.items():\n",
    "        y_pred = m.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        val_rows_sm.append({\"model\": name, \"val_accuracy\": acc, \"val_f1\": f1})\n",
    "        print(f\"\\n=== {name} (Validation) ===\")\n",
    "        print(classification_report(y_val, y_pred, digits=3))\n",
    "    pd.DataFrame(val_rows_sm).sort_values(\"val_f1\", ascending=False)\n",
    "else:\n",
    "    print(\"Skip SMOTE section (library not found).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dda826",
   "metadata": {},
   "source": [
    "## Test-set Evaluation + Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pick best model by val F1\n",
    "def best_by_val(models_dict):\n",
    "    best_name, best_model, best_f1 = None, None, -1\n",
    "    for name, m in models_dict.items():\n",
    "        f1 = f1_score(y_val, m.predict(X_val))\n",
    "        if f1 > best_f1:\n",
    "            best_name, best_model, best_f1 = name, m, f1\n",
    "    return best_name, best_model\n",
    "\n",
    "best_name, best_model = best_by_val(models)\n",
    "print(\"Best (no SMOTE):\", best_name)\n",
    "\n",
    "# If SMOTE exists, compare\n",
    "if HAS_SMOTE:\n",
    "    best_name_sm, best_model_sm = best_by_val(models_sm)\n",
    "    # Choose overall best\n",
    "    cand = [(best_name, best_model), (best_name_sm, best_model_sm)]\n",
    "    best_name, best_model = max(cand, key=lambda t: f1_score(y_val, t[1].predict(X_val)))\n",
    "    print(\"Overall best considering SMOTE:\", best_name)\n",
    "\n",
    "# Test metrics\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\n=== TEST REPORT ===\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Curves\n",
    "fig_roc = plt.figure(figsize=(6,5))\n",
    "RocCurveDisplay.from_estimator(best_model, X_test, y_test)\n",
    "plt.title(f\"Week6 ROC – {best_name}\")\n",
    "plt.savefig(os.path.join(FIG_DIR, \"week6_roc.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "fig_pr = plt.figure(figsize=(6,5))\n",
    "PrecisionRecallDisplay.from_estimator(best_model, X_test, y_test)\n",
    "plt.title(f\"Week6 Precision–Recall – {best_name}\")\n",
    "plt.savefig(os.path.join(FIG_DIR, \"week6_pr.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "import joblib\n",
    "joblib.dump(best_model, os.path.join(MODEL_DIR, \"week6_best_model.pkl\"))\n",
    "print(\"Saved model to ../models/week6_best_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
